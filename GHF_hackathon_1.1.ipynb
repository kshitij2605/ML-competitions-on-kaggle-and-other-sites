{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "df = pd.read_csv('Training Data.csv')\r\n",
    "train_data = df\r\n",
    "y = train_data['risk_flag']\r\n",
    "train_data.drop(['Id', 'risk_flag'], axis=1, inplace=True)\r\n",
    "train_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303835</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Mechanical_engineer</td>\n",
       "      <td>Rewa</td>\n",
       "      <td>Madhya_Pradesh</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Parbhani</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Technical_writer</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Civil_servant</td>\n",
       "      <td>Tiruchirappalli[10]</td>\n",
       "      <td>Tamil_Nadu</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married house_ownership car_ownership  \\\n",
       "0  1303835   23           3   single          rented            no   \n",
       "1  7574516   40          10   single          rented            no   \n",
       "2  3991815   66           4  married          rented            no   \n",
       "3  6256451   41           2   single          rented           yes   \n",
       "4  5768871   47          11   single          rented            no   \n",
       "\n",
       "            profession                 city           state  \\\n",
       "0  Mechanical_engineer                 Rewa  Madhya_Pradesh   \n",
       "1   Software_Developer             Parbhani     Maharashtra   \n",
       "2     Technical_writer            Alappuzha          Kerala   \n",
       "3   Software_Developer          Bhubaneswar          Odisha   \n",
       "4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu   \n",
       "\n",
       "   current_job_years  current_house_years  \n",
       "0                  3                   13  \n",
       "1                  9                   13  \n",
       "2                  4                   10  \n",
       "3                  2                   12  \n",
       "4                  3                   14  "
      ]
     },
     "metadata": {},
     "execution_count": 204
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "source": [
    "test_data = pd.read_csv('Test Data.csv')\r\n",
    "test_data.drop([\"id\"], axis=1, inplace=True)\r\n",
    "test_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Geologist</td>\n",
       "      <td>Malda</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>Jalna</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Latur</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>Berhampore</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married house_ownership car_ownership  \\\n",
       "0  7393090   59          19   single          rented            no   \n",
       "1  1215004   25           5   single          rented            no   \n",
       "2  8901342   50          12   single          rented            no   \n",
       "3  1944421   49           9  married          rented           yes   \n",
       "4    13429   25          18   single          rented           yes   \n",
       "\n",
       "    profession        city        state  current_job_years  \\\n",
       "0    Geologist       Malda  West Bengal                  4   \n",
       "1  Firefighter       Jalna  Maharashtra                  5   \n",
       "2       Lawyer       Thane  Maharashtra                  9   \n",
       "3      Analyst       Latur  Maharashtra                  3   \n",
       "4     Comedian  Berhampore  West Bengal                 13   \n",
       "\n",
       "   current_house_years  \n",
       "0                   13  \n",
       "1                   10  \n",
       "2                   14  \n",
       "3                   12  \n",
       "4                   11  "
      ]
     },
     "metadata": {},
     "execution_count": 205
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "source": [
    "train_data.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(252000, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "source": [
    "train_data.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252000 entries, 0 to 251999\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   income               252000 non-null  int64 \n",
      " 1   age                  252000 non-null  int64 \n",
      " 2   experience           252000 non-null  int64 \n",
      " 3   married              252000 non-null  object\n",
      " 4   house_ownership      252000 non-null  object\n",
      " 5   car_ownership        252000 non-null  object\n",
      " 6   profession           252000 non-null  object\n",
      " 7   city                 252000 non-null  object\n",
      " 8   state                252000 non-null  object\n",
      " 9   current_job_years    252000 non-null  int64 \n",
      " 10  current_house_years  252000 non-null  int64 \n",
      "dtypes: int64(5), object(6)\n",
      "memory usage: 21.1+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "source": [
    "y.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    221004\n",
       "1     30996\n",
       "Name: risk_flag, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 208
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "source": [
    "round(100 * y.value_counts()/len(train_data), 2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    87.7\n",
       "1    12.3\n",
       "Name: risk_flag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "train_data.nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "income                 41917\n",
       "age                       59\n",
       "experience                21\n",
       "married                    2\n",
       "house_ownership            3\n",
       "car_ownership              2\n",
       "profession                51\n",
       "city                     317\n",
       "state                     29\n",
       "current_job_years         15\n",
       "current_house_years        5\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 210
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "source": [
    "plt.figure(figsize=(5, 5))\r\n",
    "sns.heatmap(df.corr())"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 211
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, PowerTransformer, LabelEncoder\r\n",
    "from sklearn.preprocessing import PolynomialFeatures\r\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.neural_network import MLPClassifier\r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\r\n",
    "from sklearn.neighbors import LocalOutlierFactor\r\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\r\n",
    "from imblearn.under_sampling import RandomUnderSampler\r\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\r\n",
    "# from sklearn.pipeline import FeatureUnion\r\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\r\n",
    "import category_encoders as ce\r\n",
    "\r\n",
    "# class TypeSelector(BaseEstimator, TransformerMixin):\r\n",
    "#     def __init__(self, dtype):\r\n",
    "#         self.dtype = dtype\r\n",
    "#     def fit(self, X, y=None):\r\n",
    "#         return self\r\n",
    "#     def transform(self, X):\r\n",
    "#         assert isinstance(X, pd.DataFrame)\r\n",
    "#         return X.select_dtypes(include=[self.dtype])\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "class OutlierExtractor(TransformerMixin):\r\n",
    "    def __init__(self, **kwargs):\r\n",
    "        \"\"\"\r\n",
    "        Create a transformer to remove outliers. A threshold is set for selection\r\n",
    "        criteria, and further arguments are passed to the LocalOutlierFactor class\r\n",
    "\r\n",
    "        Keyword Args:\r\n",
    "            neg_conf_val (float): The threshold for excluding samples with a lower\r\n",
    "               negative outlier factor.\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            object: to be used as a transformer method as part of Pipeline()\r\n",
    "        \"\"\"\r\n",
    "\r\n",
    "        self.threshold = kwargs.pop('neg_conf_val', -10.0)\r\n",
    "\r\n",
    "        self.kwargs = kwargs\r\n",
    "\r\n",
    "    def transform(self, X, y):\r\n",
    "        \"\"\"\r\n",
    "        Uses LocalOutlierFactor class to subselect data based on some threshold\r\n",
    "\r\n",
    "        Returns:\r\n",
    "            ndarray: subsampled data\r\n",
    "\r\n",
    "        Notes:\r\n",
    "            X should be of shape (n_samples, n_features)\r\n",
    "        \"\"\"\r\n",
    "        X = np.asarray(X)\r\n",
    "        y = np.asarray(y)\r\n",
    "        lcf = LocalOutlierFactor(**self.kwargs)\r\n",
    "        lcf.fit(X)\r\n",
    "        return (X[lcf.negative_outlier_factor_ > self.threshold, :],\r\n",
    "                y[lcf.negative_outlier_factor_ > self.threshold])\r\n",
    "\r\n",
    "    def fit(self, *args, **kwargs):\r\n",
    "        return self"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "train_data[\"profession\"] =pd.factorize(train_data.profession, sort=True)[0]\r\n",
    "train_data[\"city\"] =pd.factorize(train_data.city, sort=True)[0]\r\n",
    "train_data[\"state\"]=pd.factorize(train_data.state, sort=True)[0]\r\n",
    "train_data[\"married\"]=pd.factorize(train_data.married, sort=True)[0]\r\n",
    "train_data[\"house_ownership\"]=pd.factorize(train_data.house_ownership, sort=True)[0]\r\n",
    "train_data[\"car_ownership\"]=pd.factorize(train_data.car_ownership, sort=True)[0]\r\n",
    "\r\n",
    "test_data[\"profession\"] = pd.factorize(test_data.profession, sort=True)[0]\r\n",
    "test_data[\"city\"] =pd.factorize(test_data.city, sort=True)[0]\r\n",
    "test_data[\"state\"]=pd.factorize(test_data.state, sort=True)[0]\r\n",
    "test_data[\"married\"]=pd.factorize(test_data.married, sort=True)[0]\r\n",
    "test_data[\"house_ownership\"]=pd.factorize(test_data.house_ownership, sort=True)[0]\r\n",
    "test_data[\"car_ownership\"]=pd.factorize(test_data.car_ownership, sort=True)[0]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "# adding in capital and cities of economic imp columns\r\n",
    "def city_features(row):\r\n",
    "    row['city']=row['city'].split('[')[0]\r\n",
    "    row['state']=row['state'].lower()\r\n",
    "    \r\n",
    "    of_economic_imp=['Chennai','Kalyan-Dombivli','Hyderabad','Malegaon','Mumbai',\r\n",
    "                     'Delhi_city','Bangalore','New_Delhi','Mira-Bhayandar','Navi_Mumbai'\r\n",
    "                    'Vasai-Virar','Kolkata','Mangalore','Jabalpur','Thane','Pune',\r\n",
    "                    'Ambarnath','Panvel','Secunderabad','Noida','Visakhapatnam',\r\n",
    "                    'Jamshedpur','Pimpri-Chinchwad','Ahmedabad','Surat','Jaipur',\r\n",
    "                    'Nagpur','Indore','Patna']\r\n",
    "    \r\n",
    "    capital_cities=['Bhopal','Pondicherry','Chennai','Shimla','Hyderabad','Aizawl',\r\n",
    "                    'Mumbai','Kochi','Srinagar','Patna','Delhi_city',\r\n",
    "                    'Chandigarh_city','Jammu','Lucknow','Bangalore','New_Delhi',\r\n",
    "                   'Imphal','Kolkata','Gangtok','Dehradun','Aizawl','Raipur',\r\n",
    "                   'Ranchi','Thiruvananthapuram','Gandhinagar','Shillong','Kohima',\r\n",
    "                   'Itanagar','Dispur','Panaji','Jaipur','Agartala']\r\n",
    "    \r\n",
    "    \r\n",
    "    row['capital']=int(str(row['city']) in capital_cities)\r\n",
    "    row['econ_imp']=int(str(row['city']) in of_economic_imp)\r\n",
    "    \r\n",
    "    return row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "def location_data(train,test,y):\r\n",
    "\r\n",
    "    train=train.apply(lambda x: city_features(x),axis=1)\r\n",
    "    test=test.apply(lambda x: city_features(x),axis=1)\r\n",
    "\r\n",
    "    train['location'] = train.city +','+ train.state\r\n",
    "    test['location'] = test.city + ','+ train.state\r\n",
    "    \r\n",
    "    train.drop(['state','city'],axis=1,inplace=True)\r\n",
    "    test.drop(['state','city'],axis=1,inplace=True)\r\n",
    "    \r\n",
    "    enc=ce.cat_boost.CatBoostEncoder(cols=['location'])\r\n",
    "    enc.fit(train,y)\r\n",
    "    \r\n",
    "    train = enc.transform(train)\r\n",
    "    test = enc.transform(test)\r\n",
    "   \r\n",
    "    return train,test"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "# train_data,test_data = location_data(train_data,test_data,y)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "# enc2=ce.cat_boost.CatBoostEncoder(cols=['profession'])\r\n",
    "# enc2.fit(train_data,y)\r\n",
    "    \r\n",
    "# train_data = enc2.transform(train_data)\r\n",
    "# test_data = enc2.transform(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "train_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303835</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>251</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>227</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>296</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married  house_ownership  car_ownership  \\\n",
       "0  1303835   23           3        1                2              0   \n",
       "1  7574516   40          10        1                2              0   \n",
       "2  3991815   66           4        0                2              0   \n",
       "3  6256451   41           2        1                2              1   \n",
       "4  5768871   47          11        1                2              0   \n",
       "\n",
       "   profession  city  state  current_job_years  current_house_years  \n",
       "0          33   251     13                  3                   13  \n",
       "1          43   227     14                  9                   13  \n",
       "2          47     8     12                  4                   10  \n",
       "3          43    54     17                  2                   12  \n",
       "4          11   296     22                  3                   14  "
      ]
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "test_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>181</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>131</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>290</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married  house_ownership  car_ownership  \\\n",
       "0  7393090   59          19        1                2              0   \n",
       "1  1215004   25           5        1                2              0   \n",
       "2  8901342   50          12        1                2              0   \n",
       "3  1944421   49           9        0                2              1   \n",
       "4    13429   25          18        1                2              1   \n",
       "\n",
       "   profession  city  state  current_job_years  current_house_years  \n",
       "0          26   181     28                  4                   13  \n",
       "1          24   131     14                  5                   10  \n",
       "2          30   290     14                  9                   14  \n",
       "3           1   171     14                  3                   12  \n",
       "4          12    39     28                 13                   11  "
      ]
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "def ratio_features(row):\r\n",
    "    #income to experience ratio\r\n",
    "    if row['experience'] != 0:\r\n",
    "        row['income_exp_ratio'] = row['income'] / row['experience']\r\n",
    "        row['age_exp_ratio'] = row['age'] / row['experience']\r\n",
    "    else:\r\n",
    "        row['income_exp_ratio']=row['income']\r\n",
    "        row['age_exp_ratio']=row['age']\r\n",
    "    \r\n",
    "    #income to current job years ratio\r\n",
    "    if row['current_job_years'] != 0:\r\n",
    "        row['income_joby_ratio'] = row['income'] / row['current_job_years']\r\n",
    "        row['age_curjob_ratio'] = row['age'] / row['current_job_years']\r\n",
    "    else:\r\n",
    "        row['income_joby_ratio'] = row['income']\r\n",
    "        row['age_curjob_ratio'] = row['age']\r\n",
    "        \r\n",
    "    return row     \r\n",
    "    \r\n",
    "def other_work_exp(row):\r\n",
    "    #probable other work exp     \r\n",
    "    #considering 25 to be the average age of starting earning:    \r\n",
    "          \r\n",
    "    if ((row['age']>35 and row['age']<45) and row['experience']<10):\r\n",
    "        row['P(oth_work)'] = row['age'] - (25+row['experience'])\r\n",
    "        \r\n",
    "    elif ((row['age']>45 and row['age']<60) and row['experience']<15):\r\n",
    "        row['P(oth_work)'] = row['age'] - (25+row['experience'])\r\n",
    "    \r\n",
    "    elif ((row['age']>65) and row['experience']<20):\r\n",
    "        row['P(oth_work)'] = row['age'] - (25+row['experience'])\r\n",
    "        \r\n",
    "    elif ((row['age']>30 and row['age']<35)and row['experience']<4):\r\n",
    "        row['P(oth_work)'] = max(row['age'] - (25+row['experience']),2)\r\n",
    "    else:\r\n",
    "        # about 2 years of workexp is req for loans\r\n",
    "        row['P(oth_work)'] = 2\r\n",
    "\r\n",
    "    return row\r\n",
    "\r\n",
    "    \r\n",
    "def create_features(train_data1):\r\n",
    "\r\n",
    "    train_data = train_data1.copy(deep=True)  \r\n",
    "    \r\n",
    "    #ratio features\r\n",
    "    train_data = train_data.apply(lambda x:ratio_features(x), axis=1)\r\n",
    "    \r\n",
    "    #age income ratio\r\n",
    "    train_data['income_age_ratio'] = train_data['income']/train_data['age']\r\n",
    "\r\n",
    "    #documented other exp\r\n",
    "    train_data['other_exp']=train_data['experience']-train_data['current_job_years']\r\n",
    "    \r\n",
    "    #probable other exp based on age\r\n",
    "    train_data=train_data.apply(lambda x: other_work_exp(x), axis=1)\r\n",
    "    \r\n",
    "    #probable total exp:\r\n",
    "    train_data['P(total_exp)'] = train_data['experience'] + train_data['P(oth_work)']\r\n",
    "    \r\n",
    "    # in working age(18-65)\r\n",
    "    train_data['working_age'] = train_data['age'].apply(lambda x : int((x>18) and (x<65)))\r\n",
    "    \r\n",
    "    #income to probable total exp:\r\n",
    "    train_data['P(income/total_exp)'] = train_data['income'] /train_data['P(total_exp)']\r\n",
    "    \r\n",
    "    #pays house rent\r\n",
    "    train_data['pays_rent'] = train_data['house_ownership'].apply(lambda x: int(x==2))\r\n",
    "    \r\n",
    "    return train_data\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "source": [
    "X = create_features(train_data)\r\n",
    "test_X = create_features(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "source": [
    "X.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['income', 'age', 'experience', 'married', 'house_ownership',\n",
       "       'car_ownership', 'profession', 'city', 'state', 'current_job_years',\n",
       "       'current_house_years', 'income_exp_ratio', 'age_exp_ratio',\n",
       "       'income_joby_ratio', 'age_curjob_ratio', 'income_age_ratio',\n",
       "       'other_exp', 'P(oth_work)', 'P(total_exp)', 'working_age',\n",
       "       'P(income/total_exp)', 'pays_rent'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 222
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\r\n",
    "\r\n",
    "def feature_selector(n_iters=10):\r\n",
    "    scores=[]\r\n",
    "    n=0\r\n",
    "    \r\n",
    "    while n <=n_iters:\r\n",
    "        feature_imp = mutual_info_classif(X,y)\r\n",
    "        scores.append(feature_imp)\r\n",
    "        n += 1\r\n",
    "        \r\n",
    "    mean_score = np.mean(a=np.array(scores), axis=0)\r\n",
    "    mutual_info = pd.Series(mean_score, index=X.columns).sort_values(ascending=False)\r\n",
    "    \r\n",
    "    return mutual_info"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "feature_selector(1)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "income_age_ratio       0.160624\n",
       "income_exp_ratio       0.159936\n",
       "income_joby_ratio      0.159873\n",
       "income                 0.159352\n",
       "P(income/total_exp)    0.159340\n",
       "house_ownership        0.043134\n",
       "pays_rent              0.042353\n",
       "married                0.039272\n",
       "working_age            0.026478\n",
       "age_exp_ratio          0.021526\n",
       "age_curjob_ratio       0.017437\n",
       "city                   0.009973\n",
       "current_house_years    0.007577\n",
       "car_ownership          0.005239\n",
       "state                  0.004292\n",
       "current_job_years      0.004171\n",
       "experience             0.003959\n",
       "P(oth_work)            0.003535\n",
       "P(total_exp)           0.002906\n",
       "other_exp              0.002346\n",
       "age                    0.002111\n",
       "profession             0.001439\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 224
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "source": [
    "X.drop(columns=['age', 'profession', 'P(total_exp)', 'other_exp', 'P(oth_work)', 'state', 'experience', 'car_ownership', 'current_job_years', 'current_house_years'], axis=1, inplace=True)\r\n",
    "\r\n",
    "X.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>city</th>\n",
       "      <th>income_exp_ratio</th>\n",
       "      <th>age_exp_ratio</th>\n",
       "      <th>income_joby_ratio</th>\n",
       "      <th>age_curjob_ratio</th>\n",
       "      <th>income_age_ratio</th>\n",
       "      <th>working_age</th>\n",
       "      <th>P(income/total_exp)</th>\n",
       "      <th>pays_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1303835.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>4.346117e+05</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>4.346117e+05</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>56688.478261</td>\n",
       "      <td>1</td>\n",
       "      <td>260767.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7574516.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>7.574516e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.416129e+05</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>189362.900000</td>\n",
       "      <td>1</td>\n",
       "      <td>631209.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3991815.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.979538e+05</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>9.979538e+05</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>60482.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>97361.341463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6256451.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>3.128226e+06</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>3.128226e+06</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>152596.365854</td>\n",
       "      <td>1</td>\n",
       "      <td>391028.187500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5768871.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>5.244428e+05</td>\n",
       "      <td>4.272727</td>\n",
       "      <td>1.922957e+06</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>122741.936170</td>\n",
       "      <td>1</td>\n",
       "      <td>262221.409091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      income  married  house_ownership   city  income_exp_ratio  \\\n",
       "0  1303835.0      1.0              2.0  251.0      4.346117e+05   \n",
       "1  7574516.0      1.0              2.0  227.0      7.574516e+05   \n",
       "2  3991815.0      0.0              2.0    8.0      9.979538e+05   \n",
       "3  6256451.0      1.0              2.0   54.0      3.128226e+06   \n",
       "4  5768871.0      1.0              2.0  296.0      5.244428e+05   \n",
       "\n",
       "   age_exp_ratio  income_joby_ratio  age_curjob_ratio  income_age_ratio  \\\n",
       "0       7.666667       4.346117e+05          7.666667      56688.478261   \n",
       "1       4.000000       8.416129e+05          4.444444     189362.900000   \n",
       "2      16.500000       9.979538e+05         16.500000      60482.045455   \n",
       "3      20.500000       3.128226e+06         20.500000     152596.365854   \n",
       "4       4.272727       1.922957e+06         15.666667     122741.936170   \n",
       "\n",
       "   working_age  P(income/total_exp)  pays_rent  \n",
       "0            1        260767.000000          1  \n",
       "1            1        631209.666667          1  \n",
       "2            0         97361.341463          1  \n",
       "3            1        391028.187500          1  \n",
       "4            1        262221.409091          1  "
      ]
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "test_X.drop(columns=['age', 'profession', 'P(total_exp)', 'other_exp', 'P(oth_work)', 'state', 'experience', 'car_ownership', 'current_job_years', 'current_house_years'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "source": [
    "# num_feat = X.select_dtypes(include='int64').columns\r\n",
    "# cat_feat = X.select_dtypes(include='object').columns\r\n",
    "# X = train_data.drop('risk_flag', axis=1)\r\n",
    "# y = train_data['risk_flag']\r\n",
    "\r\n",
    "# import category_encoders as ce\r\n",
    "\r\n",
    "# enc=ce.cat_boost.CatBoostEncoder()\r\n",
    "    \r\n",
    "# enc.fit(X,y)\r\n",
    "    \r\n",
    "# X = enc.transform(X)\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=10)\r\n",
    "\r\n",
    "# oversampling\r\n",
    "oversample = SMOTENC(categorical_features=[1,2,3], random_state=10)\r\n",
    "# oversample = SMOTE(random_state=10)\r\n",
    "X_train, y_train = oversample.fit_resample(X_train, y_train)\r\n",
    "\r\n",
    "\r\n",
    "# identify outliers in the training dataset\r\n",
    "lof = LocalOutlierFactor()\r\n",
    "yhat = lof.fit_predict(X_train)\r\n",
    "# select all rows that are not outliers\r\n",
    "mask = (yhat != -1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "source": [
    "X_train, y_train = X_train.iloc[mask], y_train.iloc[mask]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "source": [
    "print(X_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(343484, 12)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "source": [
    "print(y_train.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    177268\n",
      "1    166216\n",
      "Name: risk_flag, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "source": [
    "numeric_transformer = imb_pipeline(steps=[\r\n",
    "    ('scaler', PowerTransformer(standardize=True))\r\n",
    "])\r\n",
    "\r\n",
    "categorical_transformer = imb_pipeline(steps=[\r\n",
    "    ('one_hot', OneHotEncoder()),\r\n",
    "    # ('svd', TruncatedSVD(n_components=300))\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "num_feat = X.select_dtypes(include=['int64', 'float64']).columns\r\n",
    "cat_feat = X.select_dtypes(include='object').columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "source": [
    "preprocessor = ColumnTransformer(\r\n",
    "    transformers=[\r\n",
    "        ('num', numeric_transformer, num_feat),\r\n",
    "        ('cat', categorical_transformer, cat_feat),\r\n",
    "        # ('data', data_balancing_transformer, X.columns)\r\n",
    "    ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "source": [
    "# transformer = FeatureUnion(n_jobs=1, transformer_list=[\r\n",
    "#      # Select and scale numericals\r\n",
    "#     ('selector1', TypeSelector(np.number)),\r\n",
    "#     ('scaler', StandardScaler()),\r\n",
    "#      # Select and encode categoricals\r\n",
    "#     ('selector2', TypeSelector('category')),\r\n",
    "#     ('encoder', OneHotEncoder())\r\n",
    "# ])\r\n",
    "\r\n",
    "# pipe = Pipeline([\r\n",
    "#     ('sampler', RandomUnderSampler(sampling_strategy=0.7, random_state=10)),\r\n",
    "#     ('prep', transformer),\r\n",
    "#     ('clf', RandomForestClassifier(random_state=10))\r\n",
    "# ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "source": [
    "pipe = imb_pipeline(steps=[\r\n",
    "    ('preprocessor', preprocessor),\r\n",
    "    ('classifier',  RandomForestClassifier(n_estimators=314, max_depth=45.917518734577804, criterion='entropy', class_weight='balanced_subsample'))\r\n",
    "])\r\n",
    "\r\n",
    "model = pipe.fit(X_train, y_train)\r\n",
    "target_names = y_test.unique().astype(str)\r\n",
    "y_pred = model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "source": [
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92     22018\n",
      "           1       0.50      0.83      0.62      3182\n",
      "\n",
      "    accuracy                           0.87     25200\n",
      "   macro avg       0.73      0.85      0.77     25200\n",
      "weighted avg       0.91      0.87      0.88     25200\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "source": [
    "print(round(pd.DataFrame(confusion_matrix(y_test, y_pred)/len(y_test)*1e2)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      0     1\n",
      "0  77.0  11.0\n",
      "1   2.0  10.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "source": [
    "from sklearn.metrics import roc_auc_score\r\n",
    "\r\n",
    "print(roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9369448395430309\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "source": [
    "f1_score(y_true=y_test, y_pred=y_pred)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6202666037513271"
      ]
     },
     "metadata": {},
     "execution_count": 264
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "source": [
    "test_data = pd.read_csv('Test Data.csv')\r\n",
    "test_data.drop([\"id\"], axis=1, inplace=True)\r\n",
    "test_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_job_years</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Geologist</td>\n",
       "      <td>Malda</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>Jalna</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Latur</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>Berhampore</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married house_ownership car_ownership  \\\n",
       "0  7393090   59          19   single          rented            no   \n",
       "1  1215004   25           5   single          rented            no   \n",
       "2  8901342   50          12   single          rented            no   \n",
       "3  1944421   49           9  married          rented           yes   \n",
       "4    13429   25          18   single          rented           yes   \n",
       "\n",
       "    profession        city        state  current_job_years  \\\n",
       "0    Geologist       Malda  West Bengal                  4   \n",
       "1  Firefighter       Jalna  Maharashtra                  5   \n",
       "2       Lawyer       Thane  Maharashtra                  9   \n",
       "3      Analyst       Latur  Maharashtra                  3   \n",
       "4     Comedian  Berhampore  West Bengal                 13   \n",
       "\n",
       "   current_house_years  \n",
       "0                   13  \n",
       "1                   10  \n",
       "2                   14  \n",
       "3                   12  \n",
       "4                   11  "
      ]
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "source": [
    "test_data[\"profession\"] = pd.factorize(test_data.profession, sort=True)[0]\r\n",
    "test_data[\"city\"] =pd.factorize(test_data.city, sort=True)[0]\r\n",
    "test_data[\"state\"]=pd.factorize(test_data.state, sort=True)[0]\r\n",
    "test_data[\"married\"]=pd.factorize(test_data.married, sort=True)[0]\r\n",
    "test_data[\"house_ownership\"]=pd.factorize(test_data.house_ownership, sort=True)[0]\r\n",
    "test_data[\"car_ownership\"]=pd.factorize(test_data.car_ownership, sort=True)[0]\r\n",
    "# test_data = enc.transform(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "source": [
    "y_pred= pipe.predict(test_X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "source": [
    "ids = np.arange(1, y_pred.shape[0]+1)\r\n",
    "Dict = {'id': ids, 'risk_flag': y_pred}\r\n",
    "train_data = pd.DataFrame(Dict)\r\n",
    "train_data.to_csv(\"Submission49.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "source": [
    "import optuna\r\n",
    "\r\n",
    "def objective(trial):\r\n",
    "      n_estimators = trial.suggest_int('n_estimators', 10, 1000)\r\n",
    "      max_depth = int(trial.suggest_loguniform('max_depth', 1, 100))\r\n",
    "      criterion = trial.suggest_categorical('criterion', ['gini', 'entropy'])\r\n",
    "      pipe = imb_pipeline(steps=[\r\n",
    "      ('preprocessor', preprocessor),\r\n",
    "      ('classifier',  RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, criterion=criterion))\r\n",
    "      ])\r\n",
    "\r\n",
    "      for step in range(50):\r\n",
    "        pipe.fit(X_train, y_train)\r\n",
    "        \r\n",
    "        # Report intermediate objective value.\r\n",
    "        intermediate_value = roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1])\r\n",
    "        trial.report(intermediate_value, step)\r\n",
    "\r\n",
    "        # Handle pruning based on the intermediate value.\r\n",
    "        if trial.should_prune():\r\n",
    "            raise optuna.TrialPruned()\r\n",
    "        return intermediate_value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "source": [
    "study = optuna.create_study(direction='maximize')\r\n",
    "study.optimize(objective, n_trials=50)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[32m[I 2021-09-15 17:50:37,200]\u001b[0m A new study created in memory with name: no-name-8b63ce53-1d7f-4320-b5d4-3884d41fceb1\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 17:53:32,750]\u001b[0m Trial 0 finished with value: 0.6580965924742792 and parameters: {'n_estimators': 319, 'max_depth': 7.359515410233295, 'criterion': 'entropy'}. Best is trial 0 with value: 0.6580965924742792.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:04:09,590]\u001b[0m Trial 1 finished with value: 0.8881529362953652 and parameters: {'n_estimators': 650, 'max_depth': 17.989796107023118, 'criterion': 'gini'}. Best is trial 1 with value: 0.8881529362953652.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:07:24,557]\u001b[0m Trial 2 finished with value: 0.5697666354235399 and parameters: {'n_estimators': 660, 'max_depth': 3.4783088276696645, 'criterion': 'entropy'}. Best is trial 1 with value: 0.8881529362953652.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:09:03,141]\u001b[0m Trial 3 finished with value: 0.9223946763401796 and parameters: {'n_estimators': 84, 'max_depth': 28.898584235407167, 'criterion': 'entropy'}. Best is trial 3 with value: 0.9223946763401796.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:17:33,712]\u001b[0m Trial 4 finished with value: 0.925459636219015 and parameters: {'n_estimators': 446, 'max_depth': 26.094242894674668, 'criterion': 'gini'}. Best is trial 4 with value: 0.925459636219015.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:20:33,950]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:22:03,028]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:23:33,356]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:34:11,624]\u001b[0m Trial 8 finished with value: 0.9370959929419498 and parameters: {'n_estimators': 314, 'max_depth': 45.917518734577804, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 18:40:21,659]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:00:43,213]\u001b[0m Trial 10 finished with value: 0.9368493802482273 and parameters: {'n_estimators': 940, 'max_depth': 98.66577584509443, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:23:50,233]\u001b[0m Trial 11 finished with value: 0.9367895326371161 and parameters: {'n_estimators': 987, 'max_depth': 88.7758445650346, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:25:27,664]\u001b[0m Trial 12 finished with value: 0.9366175546103385 and parameters: {'n_estimators': 50, 'max_depth': 85.52991302565256, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:43:52,204]\u001b[0m Trial 13 finished with value: 0.9369329499508403 and parameters: {'n_estimators': 774, 'max_depth': 46.12311204734067, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:45:57,332]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 19:57:30,558]\u001b[0m Trial 15 finished with value: 0.9368060182061201 and parameters: {'n_estimators': 477, 'max_depth': 42.071263141835686, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 20:22:15,920]\u001b[0m Trial 16 finished with value: 0.9370064641700216 and parameters: {'n_estimators': 798, 'max_depth': 48.13828907379875, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 20:29:09,030]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 20:33:29,805]\u001b[0m Trial 18 finished with value: 0.9368696125374594 and parameters: {'n_estimators': 189, 'max_depth': 49.910006279493956, 'criterion': 'gini'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 20:41:39,635]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 20:45:31,430]\u001b[0m Trial 20 finished with value: 0.9368094651887298 and parameters: {'n_estimators': 129, 'max_depth': 57.87612981136962, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 21:03:23,677]\u001b[0m Trial 21 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 21:21:58,836]\u001b[0m Trial 22 finished with value: 0.9369233298006161 and parameters: {'n_estimators': 792, 'max_depth': 56.14329672967831, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 21:37:16,797]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 21:51:25,677]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 22:08:30,993]\u001b[0m Trial 25 finished with value: 0.936813754291315 and parameters: {'n_estimators': 712, 'max_depth': 66.83775551041565, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n",
      "\u001b[32m[I 2021-09-15 22:25:28,720]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 22:29:26,529]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 22:47:51,747]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 22:55:14,898]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 23:02:11,610]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2021-09-15 23:21:40,256]\u001b[0m Trial 31 finished with value: 0.9368368198147006 and parameters: {'n_estimators': 810, 'max_depth': 71.80867023352648, 'criterion': 'entropy'}. Best is trial 8 with value: 0.9370959929419498.\u001b[0m\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-244-5fc18ab2442e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    398\u001b[0m             )\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    401\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-243-88c8999473f1>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m# Report intermediate objective value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    264\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \"\"\"\n\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    904\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "source": [
    "trial = study.best_trial\r\n",
    "print('roc_auc: {}'.format(trial.value))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "roc_auc: 0.9370959929419498\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "source": [
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best hyperparameters: {'n_estimators': 314, 'max_depth': 45.917518734577804, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from time import time\r\n",
    "from sklearn.dummy import DummyClassifier\r\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
    "from sklearn.linear_model import (LogisticRegression, RidgeClassifier, \r\n",
    "                                  SGDClassifier, PassiveAggressiveClassifier)\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \r\n",
    "                              ExtraTreesClassifier, VotingClassifier)\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from lightgbm import LGBMClassifier\r\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# results = pd.DataFrame(columns=['Name', 'roc_auc', 'f1_test', 'StdDev(%)', 'Time(s)'])\r\n",
    "\r\n",
    "# for model in [\r\n",
    "#     DummyClassifier,\r\n",
    "#     LinearDiscriminantAnalysis,\r\n",
    "#     LogisticRegression, \r\n",
    "#     RidgeClassifier,\r\n",
    "#     SGDClassifier,\r\n",
    "#     PassiveAggressiveClassifier,\r\n",
    "#     GaussianNB,\r\n",
    "#     KNeighborsClassifier,\r\n",
    "#     DecisionTreeClassifier,\r\n",
    "#     RandomForestClassifier, \r\n",
    "#     GradientBoostingClassifier,\r\n",
    "#     ExtraTreesClassifier,\r\n",
    "#     MLPClassifier,\r\n",
    "#     XGBClassifier,\r\n",
    "#     LGBMClassifier\r\n",
    "# ]:\r\n",
    "\r\n",
    "#     pipe = imb_pipeline(steps=[\r\n",
    "#     ('preprocessor', preprocessor),\r\n",
    "#     ('classifier',  model())\r\n",
    "#     ])\r\n",
    "    \r\n",
    "#     start_time = time()\r\n",
    "#     kfold = StratifiedKFold(n_splits=4, random_state=1, shuffle=True)\r\n",
    "#     scores = cross_val_score(pipe, X_train, y_train, scoring='roc_auc', cv=kfold)\r\n",
    "#     pipe.fit(X_train, y_train)\r\n",
    "#     scores_test_f1 = f1_score(y_true=y_test, y_pred=pipe.predict(X_test))\r\n",
    "#     # scores_test_roc = roc_auc_score(y_test, pipe.predict_proba(X_test)[:,1])\r\n",
    "#     time_mod = time() - start_time\r\n",
    "#     results = results.append({\r\n",
    "#         'Name' : model.__name__, \r\n",
    "#         'roc_auc' : round(scores.mean(), 4), \r\n",
    "#         'f1_test' : round(scores_test_f1, 4),\r\n",
    "#         'StdDev(%)' : round(1e2*scores.std(), 2), \r\n",
    "#         'Time(s)': round(time_mod, 2)\r\n",
    "#     }, ignore_index=True)\r\n",
    "#     del pipe\r\n",
    "#     print('Analyzed {}.'.format(model.__name__))\r\n",
    "# print('Done!')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzed DummyClassifier.\n",
      "Analyzed LinearDiscriminantAnalysis.\n",
      "Analyzed LogisticRegression.\n",
      "Analyzed RidgeClassifier.\n",
      "Analyzed SGDClassifier.\n",
      "Analyzed PassiveAggressiveClassifier.\n",
      "Analyzed GaussianNB.\n",
      "Analyzed KNeighborsClassifier.\n",
      "Analyzed DecisionTreeClassifier.\n",
      "Analyzed RandomForestClassifier.\n",
      "Analyzed GradientBoostingClassifier.\n",
      "Analyzed ExtraTreesClassifier.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Analyzed MLPClassifier.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:41:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:41:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:41:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:41:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[09:42:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Analyzed XGBClassifier.\n",
      "Analyzed LGBMClassifier.\n",
      "Done!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'f1'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-5c30dfe119d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   6252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6253\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6254\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6256\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'f1'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "results = results.sort_values('roc_auc', ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>StdDev(%)</th>\n",
       "      <th>Time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.05</td>\n",
       "      <td>168.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>0.6093</td>\n",
       "      <td>0.05</td>\n",
       "      <td>213.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.9453</td>\n",
       "      <td>0.6019</td>\n",
       "      <td>0.05</td>\n",
       "      <td>9.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.08</td>\n",
       "      <td>66.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>0.06</td>\n",
       "      <td>953.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.5073</td>\n",
       "      <td>0.23</td>\n",
       "      <td>13.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2132.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.7099</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.18</td>\n",
       "      <td>209.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearDiscriminantAnalysis</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.22</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.5677</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.5674</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.18</td>\n",
       "      <td>1.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.38</td>\n",
       "      <td>5.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>1.57</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DummyClassifier</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name  roc_auc  f1_test  StdDev(%)  Time(s)\n",
       "11         ExtraTreesClassifier   0.9601   0.6040       0.05   168.75\n",
       "9        RandomForestClassifier   0.9598   0.6093       0.05   213.93\n",
       "8        DecisionTreeClassifier   0.9453   0.6019       0.05     9.31\n",
       "13                XGBClassifier   0.9449   0.6000       0.08    66.73\n",
       "7          KNeighborsClassifier   0.9369   0.5172       0.06   953.86\n",
       "14               LGBMClassifier   0.9162   0.5073       0.23    13.05\n",
       "12                MLPClassifier   0.8468   0.4080       0.30  2132.78\n",
       "10   GradientBoostingClassifier   0.7099   0.2940       0.18   209.26\n",
       "2            LogisticRegression   0.5678   0.2188       0.22     2.75\n",
       "1    LinearDiscriminantAnalysis   0.5677   0.2188       0.22     4.17\n",
       "3               RidgeClassifier   0.5677   0.2188       0.22     2.09\n",
       "6                    GaussianNB   0.5674   0.2309       0.18     1.97\n",
       "4                 SGDClassifier   0.5609   0.2119       0.38     5.79\n",
       "5   PassiveAggressiveClassifier   0.5160   0.2202       1.57     4.37\n",
       "0               DummyClassifier   0.5000   0.0000       0.00     1.37"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "source": [
    "X_train_prepared = preprocessor.fit_transform(X_train)\r\n",
    "X_test_prepared = preprocessor.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "source": [
    "from mlxtend.classifier import StackingClassifier\r\n",
    "\r\n",
    "clfs = [x for x in [ExtraTreesClassifier(), \r\n",
    "                    RandomForestClassifier(), \r\n",
    "                    DecisionTreeClassifier(),                     \r\n",
    "                    XGBClassifier(), \r\n",
    "                    #RandomForestClassifier(), \r\n",
    "                    #ExtraTreesClassifier(), \r\n",
    "                    #SVC(probability=True), \r\n",
    "                    #LogisticRegression(), \r\n",
    "                    #KNeighborsClassifier()\r\n",
    "                   ]]\r\n",
    "\r\n",
    "stack = StackingClassifier(classifiers=clfs, meta_classifier=KNeighborsClassifier())\r\n",
    "\r\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)\r\n",
    "\r\n",
    "cross_val_score(stack, X_train_prepared, y_train, scoring='f1', cv=kfold).mean()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:15:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:20:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:24:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:28:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:32:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:37:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:42:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:44:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:47:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15:51:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6074958969425857"
      ]
     },
     "metadata": {},
     "execution_count": 279
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "source": [
    "def threshold_optimizer(X_train, X_test, y_train, y_test):\r\n",
    "    scores, thresholds = [], []\r\n",
    "    for threshold in np.linspace(0, 1, 21):\r\n",
    "        y_pred = np.zeros(len(y_test))\r\n",
    "\r\n",
    "        all_models = [\r\n",
    "                    ExtraTreesClassifier(),\r\n",
    "                    RandomForestClassifier(),\r\n",
    "                    DecisionTreeClassifier(),\r\n",
    "                    XGBClassifier(),\r\n",
    "                    KNeighborsClassifier()\r\n",
    "        ]\r\n",
    "\r\n",
    "        for model in all_models:\r\n",
    "            model.fit(X_train, y_train)\r\n",
    "            y_pred += model.predict_proba(X_test)[:, 1]\r\n",
    "\r\n",
    "        y_pred /= len(all_models)\r\n",
    "        y_pred = (y_pred > threshold) * 1\r\n",
    "\r\n",
    "        thresholds.append(threshold)\r\n",
    "        scores.append(f1_score(y_test, y_pred))\r\n",
    "    return thresholds, scores"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "thresholds, scores = threshold_optimizer(X_train_prepared, X_test_prepared, y_train, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "source": [
    "plt.plot(thresholds, scores)\r\n",
    "plt.scatter(thresholds, scores)\r\n",
    "plt.legend(['f1 Scores'])\r\n",
    "plt.xlabel('Threshold')\r\n",
    "plt.ylabel('f1 Score')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'f1 Score')"
      ]
     },
     "metadata": {},
     "execution_count": 282
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "source": [
    "rnd = RandomForestClassifier()\r\n",
    "param_grid = [\r\n",
    "    {\r\n",
    "        'max_depth': [None, 2, 3, 5],\r\n",
    "        \r\n",
    "        'min_samples_leaf': [2, 4, 6, 8], \r\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None]}\r\n",
    "]\r\n",
    "\r\n",
    "grid_search = GridSearchCV(rnd, param_grid=param_grid, cv=5, scoring='roc_auc')\r\n",
    "grid_search.fit(X_train_prepared, y_train)\r\n",
    "print(grid_search.best_estimator_)\r\n",
    "grid_search.score(X_test_prepared, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestClassifier(max_features='sqrt', min_samples_leaf=2,\n",
      "                       min_samples_split=128)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9357654576545251"
      ]
     },
     "metadata": {},
     "execution_count": 284
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "source": [
    "f1_score(y_test, grid_search.predict(X_test_prepared))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6447507953340403"
      ]
     },
     "metadata": {},
     "execution_count": 286
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "source": [
    "test_data = pd.read_csv('Test Data.csv')\r\n",
    "test_data.drop([\"id\",\"current_job_years\"], axis=1, inplace=True)\r\n",
    "test_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>married</th>\n",
       "      <th>house_ownership</th>\n",
       "      <th>car_ownership</th>\n",
       "      <th>profession</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>current_house_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Geologist</td>\n",
       "      <td>Malda</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>Jalna</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Latur</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>Berhampore</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    income  age  experience  married house_ownership car_ownership  \\\n",
       "0  7393090   59          19   single          rented            no   \n",
       "1  1215004   25           5   single          rented            no   \n",
       "2  8901342   50          12   single          rented            no   \n",
       "3  1944421   49           9  married          rented           yes   \n",
       "4    13429   25          18   single          rented           yes   \n",
       "\n",
       "    profession        city        state  current_house_years  \n",
       "0    Geologist       Malda  West Bengal                   13  \n",
       "1  Firefighter       Jalna  Maharashtra                   10  \n",
       "2       Lawyer       Thane  Maharashtra                   14  \n",
       "3      Analyst       Latur  Maharashtra                   12  \n",
       "4     Comedian  Berhampore  West Bengal                   11  "
      ]
     },
     "metadata": {},
     "execution_count": 291
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "source": [
    "test_data[\"profession\"] = pd.factorize(test_data.profession, sort=True)[0]\r\n",
    "test_data[\"city\"] =pd.factorize(test_data.city, sort=True)[0]\r\n",
    "test_data[\"state\"]=pd.factorize(test_data.state, sort=True)[0]\r\n",
    "test_data[\"married\"]=pd.factorize(test_data.married, sort=True)[0]\r\n",
    "test_data[\"house_ownership\"]=pd.factorize(test_data.house_ownership, sort=True)[0]\r\n",
    "test_data[\"car_ownership\"]=pd.factorize(test_data.car_ownership, sort=True)[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "test_data = preprocessor.transform(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "source": [
    "y_pred= grid_search.predict(test_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "ids = np.arange(1, y_pred.shape[0]+1)\r\n",
    "Dict = {'id': ids, 'risk_flag': y_pred}\r\n",
    "train_data = pd.DataFrame(Dict)\r\n",
    "train_data.to_csv(\"Submission29.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "776d0385c31ec595870eb83e4f9f34eaf6a8ac0041d0d5b8230ca7bfcf3c5fb0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}